

## üì¶ Project Structure

- `ingest.py` ‚Üí Preprocess documents, split them into chunks, embed them, and store in vector DB (Chroma).
- `tcp_server.py` ‚Üí Simulates real-time sensor data from a CSV file to the ML model.
- `ML_models.py` ‚Üí Receives sensor data, predicts posture using a trained ML model, aggregates metadata, and triggers the LLM when needed.
- `run_localLLM.py` ‚Üí Starts a Flask server running a local LLM with RAG and memory to handle posture-related queries.
- `query.py` ‚Üí Allows manual user queries to be sent to the AI agent (e.g., questions about comfort, fatigue, posture recommendations).

---

## üõ†Ô∏è Step-by-Step Setup & Usage

### 1Ô∏è‚É£ Data Ingestion (RAG Setup)
Index the research documents.

```bash
python ingest.py
```

This will:
- Load source documents (PDFs, CSVs, etc.).
- Split them into context-friendly chunks.
- Generate embeddings using `Instructor-XL`.
- Store them into ChromaDB for semantic retrieval.

---

### 2Ô∏è‚É£ Start the AIO Sensor Simulator
Simulate real-time sensor streams using a TCP server (reads from a CSV file).

```bash
python tcp_server.py
```

This script:
- Reads sensor rows from your CSV.
- Streams them over a socket to the ML posture prediction module.

---

### 3Ô∏è‚É£ Run the Posture Aggregation + Trigger Engine
Start the posture prediction logic and metadata aggregation:

```bash
python ML_models.py
```

This:
- Connects to the TCP server.
- Predicts posture from incoming sensor data.
- Aggregates fatigue level, posture switches, and pressure analysis.
- Triggers the LLM when conditions are met (e.g., high fatigue).

---

### 4Ô∏è‚É£ Start the Local LLM API Server
Run the Flask server that loads the local LLM + RAG + conversational memory.

```bash
python run_localLLM.py
```

This:
- Loads the LLM and vector DB.
- Serves `/query` endpoint to respond to engineered and user queries.
- Maintains short-term memory between exchanges.

---

### 5Ô∏è‚É£ Send a Query to the Agent
Use the sample query tool to interact with the assistant:

```bash
python query.py
```

You can ask questions like:
- ‚ÄúWhat can I do to improve my posture?‚Äù
- ‚ÄúSuggest better seat adjustments based on my sitting pattern.‚Äù

---

## ‚úÖ Requirements

Use `requirements.txt`

```bash
pip install -r requirements.txt
```

---


